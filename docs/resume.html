<html>
<head>
<style type="text/css">
    html {
        font-size: 11pt;
        line-height: 1.5em;
        font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
    }
    h1 {
        font-size: 1.5em;
        line-height: 1em;
        font-weight: bold;
        margin-left: 0;
    }
    h2 {
        font-size: 1.4em;
        line-height: 1em;
        font-weight: bold;
        margin-left: 0;
        margin-bottom: 0;
    }
    h3 {
        font-size: 1.2em;
        line-height: 1em;
        font-weight: bold;
        margin-left: .5em;
    }
    p {
        margin-left: 1em;
        margin-bottom: 0;
    }
    strong {
        padding: .2em 0 .2em .4em;
    }
    a {
        color: steelblue;
        text-decoration: none;
    }
    a:hover {
        color: dodgerblue;
        text-decoration: none;
    }
    a:visited {
        color: steelblue;
        text-decoration: none;
    }
    table {
        border-collapse: collapse;
        font-size: 1em;
    }
    td, th {
        text-align: left;
        border-width: 0px;
        border-style: none;
        padding: .5em;
    }
    th {
        font-weight: bold;
    }
    code {
        padding: .2em .4em;
        margin: 0;
        background-color: rgba(27,31,35,.05);
        border-radius: 3px;
        color: #24292e;
        box-sizing: border-box;
    }
</style>
</head>
<body>
<h1>David Isaac Belais</h1>
<p>Portland OR |  503-267-0942  |
<a href="mailto:david@belais.me">david@belais.me</a> |
<a href="https://david.belais.me">david.belais.me</a> |
<a href="https://github.com/davebelais">github.com/davebelais</a></p>
<h2>Summary</h2>
<p>I am a highly productive software and data engineer with 18 years of
relevant experience.</p>
<p>I pride myself in:</p>
<ul>
<li>Creating resilient, maintainable, integrous data products</li>
<li>Authoring elegant, bulletproof, type-annotated, well-formed, thoroughly
    tested, well documented, distributable Python libraries, CLIs, web APIs,
    SDKs, and Spark jobs</li>
<li>Writing <em>readable</em> and efficient SQL</li>
<li>Designing efficient, maintainable, testable, continuously integrated
    and deployed, modern software systems</li>
<li>Planning development work with clarity, flexibility, parallel execution,
    and collaboration in mind</li>
<li>Leading engineering teams with complex and ambiguous directives towards
    clear, executable road maps</li>
<li>Condensing fact from the vapor of nuance</li>
</ul>
<h2>Skills</h2>
<p>I have professional experience with (not exhaustive):</p>
<ul>
<li>Platforms: Databricks, Snowflake, Amazon Web Services
    (AWS - including Lambda, EMR, Aurora, IAM, Cloudformation, EC2, S3)</li>
<li>Languages: Python, SQL, Javascript, C++, HTML, XML, PHP, WSDL, Rust</li>
<li>Databases and query engines: Databricks Lakehouse, Delta Lake,
    Snowflake, Terradata, Netezza, Hive, Presto, DuckDB, PostgreSQL, MySQL,
    SQL Server, Oracle, IBM DB2, SQLite, MariaDB</li>
<li>Applications, Services and Frameworks: Apache Spark, Apache Kafka,
    SQLAlchemy, FastAPI, Flask, Docker, Terraform, Linux, Unix, Github Actions,
    Jenkins, Kubernetes, Hadoop, Copilot</li>
<li>Protocols and Specifications: Open API (Swagger), SOAP, MIME,
    AS2 (for GDSN data pools), ASGI, WSGI</li>
<li>Distributed File Systems: DBFS, S3, HDFS</li>
</ul>
<h2>Experience</h2>
<h3>Nike | Lead Data Engineer - Sustainability Analytics | March 2021 - June 2025</h3>
<p><small>
<strong>Platforms:</strong> Databricks, Snowflake, Amazon Web Services
    (AWS - including Lambda, EMR, Aurora, IAM, Cloudformation, EC2, S3)<br/>
<strong>Languages:</strong> Python, SQL, Javascript<br/>
<strong>Databases and query engines:</strong> Databricks Lakehouse, Delta lake,
    Snowflake, Terradata, Hive, Presto, PostgreSQL, Oracle, SQLite<br/>
<strong>Applications, Services and Frameworks:</strong> Apache Spark, Apache Kafka,
    SQLAlchemy, Alembic, FastAPI, Terraform, Docker, Linux, Github Actions,
    Jenkins, Hadoop, Copilot<br/>
<strong>Protocols and Specifications:</strong> Open API (Swagger), ASGI<br/>
<strong>Distributed File Systems:</strong> DBFS, S3, HDFS
</small></p>
<ul>
<li>I lead and mentored a team of, variably, 4-8 data engineers in developing
    data and software products supporting analysts, data scientists,
    environmental scientists, product developers, and sustainability
    professionals in assessing and mitigating Nike's environmental impacts</li>
<li>I implemented ELT and ETL data pipelines leveraging Databricks Delta Lake
    (Python, Spark, and Spark SQL), Snowflake (Snowflake SQL), and Amazon EMR
    (Python, Spark, HQL, and Spark SQL)â€”employing patterns using batch,
    micro-batch, streaming (Apache Kafka and Spark) and Delta live tables,
    reducing compute costs by 80% as compared with equivalent legacy pipelines</li>
<li>I authored Python web APIs using FastAPI and SQLAlchemy
    on AWS Lambda, using Okta OAuth2 authentication, deployed using
    Terraform for infrastructure as code, to facilitate preemptive mitigation
    of environmental impacts by facilitating pre-manufacture scenario modeling
    in product development systems</li>
<li>I designed and built our systems for calculating material
    and product footprints as individually testable component python libraries,
    permitting  us to fully employ test-driven development, and thereby
    safely make use of continuous integration and deployment
    (CI/CD) with Jenkins and Github Actions, and permitting us to often
    release multiple features daily</li>
<li>I employed dimensional modeling and type 2 slowly changing
    dimensions in our Databricks Delta Lake, Snowflake
    databases, and (prior to 2023) S3/hive data lake in order to
    address obstacles to replicating historically
    reported metrics (required for regulatory audits)</li>
<li>I authored foundational data products exposing Environmental Health &amp;
    Safety data from our 3rd-party EHS reporting system, Enablon, incrementally
    ingested via their Blink OData API, into our Databricks Delta Lake,
    Snowflake, and (prior to 2023) S3 + hive/presto data lake</li>
<li>I authored enterprise developer tools including python CLIs (command line
    interfaces), libraries, and SDKs (internal and 3rd party) for CI/CD
    job deployment and orchestration on Databricks and Airflow, for
    data validation, generating data model diagrams, schema versioning and
    migration, and extending SQLAlchemy's ORM for simultaneous
    multi-dialect support and view management supporting OLAP databases
    including Databricks Deltalake, Snowflake, and Hive/HQL</li>
</ul>
<h3>BICP @ Nike | Lead Data Engineer - Sustainability Analytics | March 2020 - March 2021</h3>
<p><small>
<strong>Platforms:</strong> Snowflake, Amazon Web Services
    (AWS - including Lambda, EMR, Aurora, IAM, Cloudformation, EC2, S3)<br/>
<strong>Languages:</strong> Python, SQL, Rust<br/>
<strong>Databases and query engines:</strong> Snowflake, Terradata, Hive, Presto,
    PostgreSQL, Oracle, SQLite <br/>
<strong>Applications, Services and Frameworks:</strong> Apache Spark,
    SQLAlchemy, Alembic, Docker, Linux, Terraform, Github Actions,
    Jenkins, Hadoop<br/>
<strong>Protocols and Specifications:</strong> Open API (Swagger)<br/>
<strong>Distributed File Systems:</strong> S3, HDFS
</small></p>
<p>I lead a team of data engineers in building foundational data products
supporting sustainability initiatives:</p>
<ul>
<li>I developed a SQLAlchemy-ORM-based framework for automating deployment and
    versioning (schema migration) supporting all database dialects leveraged
    by the Nike Enterprise Data &amp; Analytics organization: Databricks,
    Snowflake, Hive/Presto on S3, and PostgreSQL with full rollback
    and versioning support.</li>
<li>I authored a framework for Sustainability Analytics' ETL jobs
    incorporating end-to-end schema-based data validations, local testing, and
    environment and file system abstraction.</li>
</ul>
<h3>BICP @ Nike | Senior Data Engineer - Sustainability Analytics | January 2020 - March 2020</h3>
<p><small>
<strong>Platforms:</strong> Snowflake, Amazon Web Services
    (AWS - including Lambda, EMR, Aurora, IAM, Cloudformation, EC2, S3)<br/>
<strong>Languages:</strong> Python, SQL, Rust<br/>
<strong>Databases and query engines:</strong> Snowflake, Terradata, Hive, Presto,
    PostgreSQL, Oracle, SQLite<br/>
<strong>Applications, Services and Frameworks:</strong> Apache Spark, SQLAlchemy, Alembic,
    Docker, Linux, Jenkins, Hadoop<br/>
<strong>Protocols and Specifications:</strong> Open API (Swagger), ASGI<br/>
<strong>Distributed File Systems:</strong> S3, HDFS<br/>
<strong>Infrastructure as Code:</strong> Terraform
</small></p>
<h3>The Kroger Co. | Lead Data Engineer - Web &amp; Digital Analytics | May 2018 - November 2019</h3>
<p><small>
<strong>Languages:</strong> Python, SQL, Javascript, HTML, XML, WSDL<br/>
<strong>Databases and query engines:</strong> Netezza, Hive, Presto, SQL Server, IBM DB2,
    SQLite<br/>
<strong>Applications, Services and Frameworks:</strong>  SQLAlchemy, Flask, Hadoop,
    Magento Commerce, IBM Websphere Commerce<br/>
<strong>Protocols and Specifications:</strong> Open API (Swagger), SOAP, MIME,
    AS2 (for GDSN data pools), WSGI<br/>
</small></p>
<p>I lead development of:</p>
<ul>
<li>Data products distilling and exposing analytics to
    buyers and planners correlating digital and store sales and EBITDA with
    inventory,sell-through, prices, and promotional events&#8212;contributing
    to decisions resulting in a 56% increase in e-commerce sales in 2018 vs
    2017, and a 67% increase in ecommerce sales in 2019 vs 2018.</li>
<li>Pricing/promotions and product information integration services for
    Magento Commerce.</li>
</ul>
<!--
Note: the header above conveys a genericized role name based on current
industry usage, for clarity. My official title was "Senior Manager, Web &
Digital Analytics".
-->

<h3>The Kroger Co. | Lead Data Engineer - Product Information Management | November 2013 - May 2018</h3>
<p><small>
<strong>Languages:</strong> Python, SQL, Javascript, HTML, XML, WSDL<br/>
<strong>Databases and query engines:</strong> Netezza, Hive, Presto, SQL Server, IBM DB2,
    SQLite<br/>
<strong>Applications, Services and Frameworks:</strong>  SQLAlchemy, Flask, Hadoop<br/>
<strong>Protocols and Specifications:</strong> SOAP, MIME, AS2 (for GDSN data pools), WSGI
</small></p>
<ul>
<li>I lead development of multi-platform (Spark/Hive/Presto, Netezza, DB2,
    Python, SQL Server, SQLAlchemy)
    OLAP and OLTP data products to ingest, consolidate and normalize sales,
    dimensional, and click-stream data from disparate subsidiary and partner
    systems' transactional databases, streaming platforms, APIs, and
    mainframes.</li>
<li>I engineered algorithms for scoring semi-structured data and performing
    human-in-the loop data validation and auditing for product descriptions,
    specifications and photography acquired through trading partners
    (Python, SQL).</li>
<li>I established source-management capabilities for inbound data to handle
    complex retailer/vendor/manufacturer relationships (Python, SQL).</li>
<li>Collaborated with emerging digital initiatives to ensure the capture of all
    metrics needed to facilitate accountability and continuous operational
    improvement.</li>
</ul>
<!--
Note: the header above conveys a genericized role name based on current
industry usage, for clarity. My official title was "Manager, Web & Digital
Content".
-->

<h3>The Kroger Co. (Fred Meyer Stores Inc.) | Business Systems Analyst - Ecommerce | March 2011 - November 2013</h3>
<p><small>
<strong>Languages:</strong> Python, SQL, Javascript, HTML, XML, WSDL<br/>
<strong>OLTP Databases:</strong> SQL Server, IBM DB2, SQLite<br/>
<strong>Applications, Services and Frameworks:</strong> SQLAlchemy<br/>
<strong>Protocols and Specifications:</strong> SOAP, MIME, AS2 (for GDSN data pools)
</small></p>
<ul>
<li>I researched, designed, and prototyped Fred Meyer's (and later Kroger's)
    product information management system for <a href="https://fredmeyer.com">customer-facing digital
    initiatives</a>.</li>
<li>I collaborated with Fred Meyer's technology partner, 1WorldSync, to
    establish a roadmap, data model, and procedures for sourcing and validating
    product data from <a href="https://www.gs1.org/services/gdsn">GDSN</a> data pools for
    use in digital sales channels.</li>
</ul>
<h3>Dissent Graphics Inc. | Full-Stack Developer | January 2008 - March 2011</h3>
<p><small>
<strong>Languages:</strong> Python, PHP, SQL, Javascript, Actionscript
</small></p>
<ul>
<li>I designed and developed web applications for clients including:
    The Garrigan Lyman Group, Microsoft, Best Buy, Avenue A Razorfish,
    Nereus Communications, BlackEyedPeas.com, TeeFury.com, the Travel Channelâ€™s
    Man v. Food, TheWho.com, Custom Rights, Hello Minor, ExoticTravelers.com,
    and the ACLU of Oregon.</li>
</ul>
<h2>Education</h2>
<ul>
<li>Portland State University | Computer Science (Postbaccalaureate) | 2018</li>
<li>The Art Institute of Portland | Conmputer Generated Imaging, Visual Effect &amp;
    Animation | Bachelor of Science | 2007</li>
<li>Portland State University | Web Design | 2002 - 2004</li>
<li>Loyola Marymount University | Fine Arts | 2000 - 2001</li>
</ul>
<h2>Open Source Projects</h2>
<p>...because code examples are worth a thousand interview questions!</p>
<ul>
<li><a href="https://github.com/enorganic/git-author-stats#git-author-stats">git-author-stats</a>:
    A CLI and library for extracting periodic author "stats" (insertions and
    deletions) for a Git repository or Github organization</li>
<li><a href="https://dependence.enorganic.org/">dependence</a>:
    A CLI and library for aligning a python projects' declared dependencies with the package versions installed in the environment in which dependence is executed, and for "freezing" recursively resolved package dependencies (like pip freeze, but for a package, instead of the entire environment).</li>
<li><a href="https://maya-zen-tools.enorganic.org/">maya-zen-tools</a>:
    An Autodesk Maya extension providing modeling tools for
    manipulating a polygon mesh using dynamically created NURBS curves and
    surfaces to distribute vertices and/or UVs</li>
<li><a href="https://oapi.enorganic.org/">oapi</a>: A python library for generating client
    SDKs from Open API documents</li>
<li><a href="https://gittable.enorganic.org/">gittable</a>: A CLI and library for
    performing common, but complex, development and CI/CD tasks for a Git
    repository, such as tagging a commit with your current project/package
    version and downloading or accessing specific file(s) from a remote
    repository (including non-public repos)</li>
</ul>
<p>Please see <a href="https://github.com/davebelais">github.com/davebelais</a>
and <a href="https://github.com/enorganic">github.com/enorganic</a> for additional code
examples.</p>
<h2>Certifications</h2>
<ul>
<li><a href="https://university.atlassian.com/student/award/SbuF34YQEXwk3oDXv1coga2H">JQL for Admins</a></li>
<li><a href="https://university.atlassian.com/student/award/KPXH8RPefKoMhjUno6PSfQkA">Jira Automation for Admins</a></li>
<li><a href="https://www.youracclaim.com/badges/c9885f75-2b4e-42ea-b499-0f99eee3b7e9/public_url">AWS Certified Big Data - Specialty</a></li>
<li><a href="https://www.youracclaim.com/badges/68b84f25-96ee-4796-ac16-4c625ef4aadd/public_url">AWS Certified Cloud Practitioner</a></li>
</ul>
</body>
</html>
